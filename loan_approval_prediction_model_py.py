# -*- coding: utf-8 -*-
"""Loan Approval Prediction Model.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Osurg8jHEMZcWR9_7CkGaTOExlAhY_fU
"""

# 1. Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# To ignore warnings
import warnings
warnings.filterwarnings('ignore')

# 2. Load the Dataset
df = pd.read_csv("/content/loan_data_set.csv")

# Display first 5 rows
# df.head()
rows, columns = df.shape
print(f"Rows: {rows}, Columns: {columns}")
df.head()

# 3. Data Preprocessing

# Check for missing values
print(df.isnull().sum())

# Fill missing values
# Check if mode is not empty before filling
if df['Gender'].mode().empty:
    df['Gender'].fillna(df['Gender'].mode().iloc[0] if not df['Gender'].mode().empty else 'Unknown', inplace=True) # Use .iloc[0] and handle empty mode
else:
    df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)

df['Dependents'] = pd.to_numeric(df['Dependents'].astype(str).str.replace('+', ''), errors='coerce')
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)
df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)


# Check if 'Loan_ID' column exists before dropping
if 'Loan_ID' in df.columns:
    # Drop 'Loan_ID' column (not relevant)
    df.drop('Loan_ID', axis=1, inplace=True)
else:
    print("Loan_ID column not found in the DataFrame.")

# Encode categorical variables
le = LabelEncoder()
categorical_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# Convert target variable: Y -> 1, N -> 0
df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})

print(df.isnull().sum())

# 4. Exploratory Data Analysis (EDA)
df['Dependents'] = df['Dependents'].astype(str).str.replace('+', '').astype(float)

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Feature Correlation Heatmap")
plt.show()

# Countplot - Loan approval by Credit History
sns.countplot(x='Credit_History', hue='Loan_Status', data=df)
plt.title("Loan Approval by Credit History")
plt.legend(title='Approved (1) / Not Approved (0)')
plt.show()

# Boxplot: Applicant Income vs Loan Approval
plt.figure(figsize=(8, 6))
# Drop rows with NaN values in 'Loan_Status' before plotting
df_cleaned = df.dropna(subset=['Loan_Status'])
sns.boxplot(x='Loan_Status', y='ApplicantIncome', data=df_cleaned)
plt.title('Applicant Income vs Loan Approval')
plt.xlabel('Loan Status (0 = Rejected, 1 = Approved)')
plt.ylabel('Applicant Income')
plt.xticks([0, 1], ['Rejected', 'Approved'])
plt.grid(True)
plt.show()

# Distribution Plot: Loan Amount
plt.figure(figsize=(8, 6))
sns.histplot(df['LoanAmount'], kde=True, bins=30, color='skyblue')
plt.title('Distribution of Loan Amount')
plt.xlabel('Loan Amount (in thousands)')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# 5. Define Features (X) and Target (y)
X = df.drop('Loan_Status', axis=1)
y = df['Loan_Status']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Model Training and Evaluation

# Initialize Models
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}

# Train and evaluate each model
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    results[name] = acc
    print(f"\n{name} Accuracy: {acc:.2%}")
    print(classification_report(y_test, preds))

# 7. Compare Model Accuracies
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 5))
sns.barplot(x=list(results.keys()), y=list(results.values()))
plt.title("Model Comparison - Accuracy")
plt.ylabel("Accuracy")
plt.ylim(0.7, 1)
plt.show()

# 8. Confusion Matrix for Best Model (Random Forest)
best_model = RandomForestClassifier()
best_model.fit(X_train, y_train)
preds = best_model.predict(X_test)

cm = confusion_matrix(y_test, preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.model_selection import GridSearchCV

# Define the parameter grid for RandomForestClassifier
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')

# Fit GridSearchCV to the training data
grid_search.fit(X_train, y_train)

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f"Best Parameters: {best_params}")
print(f"Best Cross-Validation Accuracy: {best_score:.2%}")

import joblib
from sklearn.ensemble import RandomForestClassifier

# Train the best model with the best parameters
best_rf_model = RandomForestClassifier(**best_params, random_state=42)
best_rf_model.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(best_rf_model, 'best_random_forest_model.pkl')

print("Best model saved to best_random_forest_model.pkl")

import joblib
import pandas as pd

# Load the saved model
loaded_model = joblib.load('best_random_forest_model.pkl')

def predict_loan_status(data):
    """
    Predicts the loan status based on input data using the loaded model.

    Args:
        data (dict): A dictionary containing the features for prediction.
                     The keys should match the column names used during training.

    Returns:
        int: The predicted loan status (0 for rejected, 1 for approved).
    """
    # Convert the input data to a pandas DataFrame
    input_df = pd.DataFrame([data])

    # Ensure the columns are in the same order as during training
    # You might need to adjust this based on your specific feature order
    # For simplicity, assuming the input data dictionary has keys in the correct order
    # If not, you'll need to reorder columns or use a predefined list of columns
    # Example: input_df = input_df[X_train.columns]

    # Make the prediction
    prediction = loaded_model.predict(input_df)

    return int(prediction[0])

# Example usage:
# Create a sample data dictionary with the same features as your training data
sample_data = {
    'Gender': 1,
    'Married': 1,
    'Dependents': 1.0,
    'Education': 0,
    'Self_Employed': 0,
    'ApplicantIncome': 5000,
    'CoapplicantIncome': 1000,
    'LoanAmount': 150.0,
    'Loan_Amount_Term': 360.0,
    'Credit_History': 1.0,
    'Property_Area': 2
}

predicted_status = predict_loan_status(sample_data)
print(f"The predicted loan status is: {predicted_status} (0: Rejected, 1: Approved)")

!pip install streamlit

import streamlit as st
import joblib
import pandas as pd

# Load the saved model
# Make sure the path matches where you saved the model
try:
    loaded_model = joblib.load('best_random_forest_model.pkl')
except FileNotFoundError:
    st.error("Model file not found. Please make sure 'best_random_forest_model.pkl' is in the correct directory.")
    st.stop()

def predict_loan_status(data):
    """
    Predicts the loan status based on input data using the loaded model.

    Args:
        data (dict): A dictionary containing the features for prediction.
                     The keys should match the column names used during training.

    Returns:
        int: The predicted loan status (0 for rejected, 1 for approved).
    """
    # Convert the input data to a pandas DataFrame
    input_df = pd.DataFrame([data])

    # Ensure the columns are in the same order as during training
    # It's highly recommended to save and load the column order during deployment
    # For this example, we'll assume the user inputs in the correct order
    # A more robust solution would explicitly define and order columns here.

    # Make the prediction
    prediction = loaded_model.predict(input_df)

    return int(prediction[0])

# Streamlit App Interface
st.title("Loan Prediction App")

st.write("Enter the applicant's details to predict the loan status.")

# Create input fields for the features
# You'll need to create input widgets for all the features your model expects
# Based on your training data, these seem to be:
# 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',
# 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term',
# 'Credit_History', 'Property_Area'

# Example input fields (adjust based on your data's encoding and types)
# For simplicity, using numerical inputs where possible based on preprocessing
gender = st.selectbox("Gender", [0, 1], format_func=lambda x: 'Male' if x == 1 else 'Female') # Assuming 1 for Male, 0 for Female based on preprocessing
married = st.selectbox("Married", [0, 1], format_func=lambda x: 'Yes' if x == 1 else 'No') # Assuming 1 for Yes, 0 for No

# Convert float options to strings for selectboxes
dependents_options = [str(int(x)) if x != 3.0 else '3+' for x in [0.0, 1.0, 2.0, 3.0]]
dependents_display = st.selectbox("Dependents", dependents_options)
# Convert back to float for prediction
dependents = 3.0 if dependents_display == '3+' else float(dependents_display)


education = st.selectbox("Education", [0, 1], format_func=lambda x: 'Graduate' if x == 0 else 'Not Graduate') # Assuming 0 for Graduate, 1 for Not Graduate
self_employed = st.selectbox("Self Employed", [0, 1], format_func=lambda x: 'Yes' if x == 1 else 'No') # Assuming 1 for Yes, 0 for No
applicant_income = st.number_input("Applicant Income", min_value=0)
coapplicant_income = st.number_input("Coapplicant Income", min_value=0.0)
loan_amount = st.number_input("Loan Amount", min_value=0.0)

loan_amount_term_options = [str(int(x)) for x in [12.0, 36.0, 60.0, 84.0, 120.0, 180.0, 240.0, 300.0, 360.0, 480.0]]
loan_amount_term_display = st.selectbox("Loan Amount Term (in days)", loan_amount_term_options)
loan_amount_term = float(loan_amount_term_display)

credit_history_options = [str(int(x)) for x in [0.0, 1.0]]
credit_history_display = st.selectbox("Credit History", credit_history_options, format_func=lambda x: 'Yes' if x == '1' else 'No')
credit_history = float(credit_history_display)


property_area = st.selectbox("Property Area", [0, 1, 2], format_func=lambda x: 'Rural' if x == 0 else ('Semiurban' if x == 1 else 'Urban')) # Assuming 0 for Rural, 1 for Semiurban, 2 for Urban


# Create a dictionary with the input data
input_data = {
    'Gender': gender,
    'Married': married,
    'Dependents': dependents,
    'Education': education,
    'Self_Employed': self_employed,
    'ApplicantIncome': applicant_income,
    'CoapplicantIncome': coapplicant_income,
    'LoanAmount': loan_amount,
    'Loan_Amount_Term': loan_amount_term,
    'Credit_History': credit_history,
    'Property_Area': property_area
}

if st.button("Predict"):
    # Make prediction
    predicted_status = predict_loan_status(input_data)

    # Display the prediction
    if predicted_status == 1:
        st.success("Loan Status: Approved")
    else:
        st.error("Loan Status: Rejected")

st.markdown("---")
st.write("Note: This is a simple demonstration. For a production application, consider more robust input validation and error handling.")

"""**Explanation of the `Dockerfile`:**

*   **`FROM python:3.8-slim`**: Starts with a lightweight Python 3.8 image.
*   **`WORKDIR /app`**: Sets the working directory inside the container to `/app`.
*   **`COPY . /app`**: Copies all files from your current directory (where the Dockerfile is) into the `/app` directory in the container.
*   **`RUN pip install --no-cache-dir -r requirements.txt`**: Installs the Python dependencies listed in a `requirements.txt` file. **You will need to create this file** with the required libraries (like `flask`, `pandas`, `scikit-learn`, `joblib`).
*   **`EXPOSE 5000`**: Informs Docker that the container listens on port 5000 at runtime.
*   **`ENV FLASK_APP=app.py`**: Sets an environment variable to tell Flask where to find the application. **Make sure this matches the name of your Flask application file.**
*   **`CMD ["flask", "run", "--host=0.0.0.0"]`**: Specifies the command to run when the container starts, which is to start the Flask development server and make it accessible externally.

**Next Steps:**

1.  **Create a `requirements.txt` file**: List all the Python libraries your project needs (e.g., `flask`, `pandas`, `scikit-learn`, `joblib`).
2.  **Save your Flask app code**: Ensure your Flask code is saved in a file (e.g., `app.py`).
3.  **Save the trained model**: Make sure your `best_random_forest_model.pkl` file is in the same directory.
4.  **Build the Docker image**: Open your terminal in the directory containing the Dockerfile and run `docker build -t loan_prediction_app .`
5.  **Run the Docker container**: Run `docker run -p 5000:5000 loan_prediction_app`.
"""

# Save the Streamlit app code to a Python file
streamlit_code = """
import streamlit as st
import joblib
import pandas as pd

# Load the saved model
# Make sure the path matches where you saved the model
try:
    loaded_model = joblib.load('best_random_forest_model.pkl')
except FileNotFoundError:
    st.error("Model file not found. Please make sure 'best_random_forest_model.pkl' is in the correct directory.")
    st.stop()

def predict_loan_status(data):
    \"\"\"
    Predicts the loan status based on input data using the loaded model.

    Args:
        data (dict): A dictionary containing the features for prediction.
                     The keys should match the column names used during training.

    Returns:
        int: The predicted loan status (0 for rejected, 1 for approved).
    \"\"\"
    # Convert the input data to a pandas DataFrame
    input_df = pd.DataFrame([data])

    # Ensure the columns are in the same order as during training
    # It's highly recommended to save and load the column order during deployment
    # For this example, we'll assume the user inputs in the correct order
    # A more robust solution would explicitly define and order columns here.

    # Make the prediction
    prediction = loaded_model.predict(input_df)

    return int(prediction[0])

# Streamlit App Interface
st.title("Loan Prediction App")

st.write("Enter the applicant's details to predict the loan status.")

# Create input fields for the features
# You'll need to create input widgets for all the features your model expects
# Based on your training data, these seem to be:
# 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',
# 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term',
# 'Credit_History', 'Property_Area'

# Example input fields (adjust based on your data's encoding and types)
# For simplicity, using numerical inputs where possible based on preprocessing
gender = st.selectbox("Gender", [0, 1], format_func=lambda x: 'Male' if x == 1 else 'Female') # Assuming 1 for Male, 0 for Female based on preprocessing
married = st.selectbox("Married", [0, 1], format_func=lambda x: 'Yes' if x == 1 else 'No') # Assuming 1 for Yes, 0 for No

# Convert float options to strings for selectboxes
dependents_options = [str(int(x)) if x != 3.0 else '3+' for x in [0.0, 1.0, 2.0, 3.0]]
dependents_display = st.selectbox("Dependents", dependents_options)
# Convert back to float for prediction
dependents = 3.0 if dependents_display == '3+' else float(dependents_display)


education = st.selectbox("Education", [0, 1], format_func=lambda x: 'Graduate' if x == 0 else 'Not Graduate') # Assuming 0 for Graduate, 1 for Not Graduate
self_employed = st.selectbox("Self Employed", [0, 1], format_func=lambda x: 'Yes' if x == 1 else 'No') # Assuming 1 for Yes, 0 for No
applicant_income = st.number_input("Applicant Income", min_value=0)
coapplicant_income = st.number_input("Coapplicant Income", min_value=0.0)
loan_amount = st.number_input("Loan Amount", min_value=0.0)

loan_amount_term_options = [str(int(x)) for x in [12.0, 36.0, 60.0, 84.0, 120.0, 180.0, 240.0, 300.0, 360.0, 480.0]]
loan_amount_term_display = st.selectbox("Loan Amount Term (in days)", loan_amount_term_options)
loan_amount_term = float(loan_amount_term_display)

credit_history_options = [str(int(x)) for x in [0.0, 1.0]]
credit_history_display = st.selectbox("Credit History", credit_history_options, format_func=lambda x: 'Yes' if x == '1' else 'No')
credit_history = float(credit_history_display)


property_area = st.selectbox("Property Area", [0, 1, 2], format_func=lambda x: 'Rural' if x == 0 else ('Semiurban' if x == 1 else 'Urban')) # Assuming 0 for Rural, 1 for Semiurban, 2 for Urban


# Create a dictionary with the input data
input_data = {
    'Gender': gender,
    'Married': married,
    'Dependents': dependents,
    'Education': education,
    'Self_Employed': self_employed,
    'ApplicantIncome': applicant_income,
    'CoapplicantIncome': coapplicant_income,
    'LoanAmount': loan_amount,
    'Loan_Amount_Term': loan_amount_term,
    'Credit_History': credit_history,
    'Property_Area': property_area
}

if st.button("Predict"):
    # Make prediction
    predicted_status = predict_loan_status(input_data)

    # Display the prediction
    if predicted_status == 1:
        st.success("Loan Status: Approved")
    else:
        st.error("Loan Status: Rejected")

st.markdown("---")
st.write("Note: This is a simple demonstration. For a production application, consider more robust input validation and error handling.")
"""

with open('app.py', 'w') as f:
    f.write(streamlit_code)

print("Streamlit app code saved to app.py")

# Install pyngrok
!pip install pyngrok

from google.colab import userdata
userdata.get('NGROK_AUTH_TOKEN')

from pyngrok import ngrok
import os
from google.colab import userdata

# Get ngrok auth token from Colab secrets
# You need to add your ngrok auth token to Colab secrets
# Go to "🔑" in the left panel, click "Add a new secret",
# and add your auth token with the name "NGROK_AUTH_TOKEN"
# If you don't have an ngrok auth token, you can get one from https://dashboard.ngrok.com/get-started/your-authtoken
try:
    NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
except userdata.SecretNotFoundError:
    print("Your ngrok auth token is not set in Colab secrets.")
    print("Please go to '🔑' in the left panel, click 'Add a new secret',")
    print("and add your auth token with the name 'NGROK_AUTH_TOKEN'")
    print("You can get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken")
    # Stop execution if auth token is not set
    raise

# Terminate any existing ngrok tunnels
ngrok.kill()

# Open a tunnel to the Streamlit port (default is 8501)
public_url = ngrok.connect(addr="8501", proto="http")

print(f"Streamlit app available at: {public_url}")

# To keep the tunnel open, you need to run this cell and keep it executing.
# If the cell finishes execution, the tunnel will close.